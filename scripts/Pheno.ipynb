{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import seaborn as sns\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "project_root = os.path.dirname(os.path.dirname(os.path.abspath('Pheno.ipynb')))\n",
    "src_path = os.path.join(project_root, 'src')\n",
    "sys.path.append(src_path)\n",
    "%load_ext autoreload \n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Liver Cancer datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/Liver\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     10\u001b[0m string \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcell_by_gene\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 11\u001b[0m csv_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(\u001b[43mfind_csv_filenames\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstring\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(csv_files)\n\u001b[1;32m     13\u001b[0m metadata_files \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(find_csv_filenames(path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m, in \u001b[0;36mfind_csv_filenames\u001b[0;34m(path_to_dir, string_in_filename)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_csv_filenames\u001b[39m(path_to_dir, string_in_filename):\n\u001b[0;32m----> 2\u001b[0m     filenames \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39mlistdir(path_to_dir)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [filename \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m filenames \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m([\n\u001b[1;32m      4\u001b[0m         filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      5\u001b[0m         string_in_filename \u001b[38;5;129;01min\u001b[39;00m filename\n\u001b[1;32m      6\u001b[0m     ])]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "def find_csv_filenames(path_to_dir, string_in_filename):\n",
    "    filenames = os.listdir(path_to_dir)\n",
    "    return [filename for filename in filenames if all([\n",
    "        filename.endswith('.csv'),\n",
    "        string_in_filename in filename\n",
    "    ])]\n",
    "\n",
    "# 示例用法\n",
    "path = '../data/Liver'\n",
    "string = 'cell_by_gene'\n",
    "csv_files = sorted(find_csv_filenames(path, string))\n",
    "print(csv_files)\n",
    "metadata_files = sorted(find_csv_filenames(path, 'metadata'))\n",
    "print(metadata_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTA2</th>\n",
       "      <th>ACTG2</th>\n",
       "      <th>ADAM12</th>\n",
       "      <th>ADAM28</th>\n",
       "      <th>ADGRE5</th>\n",
       "      <th>ADH1B</th>\n",
       "      <th>CCL21</th>\n",
       "      <th>AIM2</th>\n",
       "      <th>ANKRD55</th>\n",
       "      <th>AREG</th>\n",
       "      <th>...</th>\n",
       "      <th>Blank-51</th>\n",
       "      <th>Blank-52</th>\n",
       "      <th>Blank-53</th>\n",
       "      <th>Blank-54</th>\n",
       "      <th>Blank-55</th>\n",
       "      <th>Blank-56</th>\n",
       "      <th>Blank-57</th>\n",
       "      <th>Blank-58</th>\n",
       "      <th>Blank-59</th>\n",
       "      <th>Blank-60</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131421</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131422</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131423</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131424</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131425</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131426 rows × 461 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ACTA2  ACTG2  ADAM12  ADAM28  ADGRE5  ADH1B  CCL21  AIM2  ANKRD55  \\\n",
       "cell                                                                        \n",
       "0         0.0    0.0     0.0     0.0     0.0    0.0    0.0   0.0      0.0   \n",
       "1         0.0    0.0     0.0     0.0     0.0    0.0    0.0   0.0      0.0   \n",
       "2         0.0    0.0     0.0     0.0     0.0    4.0    7.0   0.0      0.0   \n",
       "3         0.0    0.0     0.0     0.0     0.0    0.0   12.0   0.0      0.0   \n",
       "4         1.0    0.0     1.0     0.0     0.0    5.0    9.0   0.0      0.0   \n",
       "...       ...    ...     ...     ...     ...    ...    ...   ...      ...   \n",
       "131421    1.0    0.0     0.0     0.0     4.0    2.0   15.0   0.0      0.0   \n",
       "131422    0.0    0.0     0.0     0.0     3.0    1.0    3.0   0.0      0.0   \n",
       "131423    0.0    0.0     0.0     0.0     0.0    0.0    0.0   0.0      0.0   \n",
       "131424    0.0    0.0     0.0     0.0     3.0    0.0   10.0   0.0      0.0   \n",
       "131425    0.0    0.0     0.0     0.0     0.0    1.0    5.0   0.0      0.0   \n",
       "\n",
       "        AREG  ...  Blank-51  Blank-52  Blank-53  Blank-54  Blank-55  Blank-56  \\\n",
       "cell          ...                                                               \n",
       "0        0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1        0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "2        0.0  ...       0.0       1.0       0.0       0.0       0.0       0.0   \n",
       "3        0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "4        0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "...      ...  ...       ...       ...       ...       ...       ...       ...   \n",
       "131421   0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "131422   0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "131423   0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "131424   0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "131425   0.0  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "        Blank-57  Blank-58  Blank-59  Blank-60  \n",
       "cell                                            \n",
       "0            0.0       0.0       0.0       0.0  \n",
       "1            0.0       0.0       0.0       0.0  \n",
       "2            0.0       0.0       0.0       0.0  \n",
       "3            0.0       0.0       0.0       0.0  \n",
       "4            0.0       0.0       0.0       0.0  \n",
       "...          ...       ...       ...       ...  \n",
       "131421       0.0       0.0       0.0       0.0  \n",
       "131422       0.0       0.0       0.0       0.0  \n",
       "131423       0.0       0.0       0.0       0.0  \n",
       "131424       0.0       0.0       0.0       0.0  \n",
       "131425       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[131426 rows x 461 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_matrix = pd.read_csv(os.path.join(path, csv_files[i]), index_col=0)\n",
    "exp_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ACTA2', 'ACTG2', 'ADAM12', 'ADAM28', 'ADGRE5', 'ADH1B', 'CCL21',\n",
      "       'AIM2', 'ANKRD55', 'AREG',\n",
      "       ...\n",
      "       'Blank-51', 'Blank-52', 'Blank-53', 'Blank-54', 'Blank-55', 'Blank-56',\n",
      "       'Blank-57', 'Blank-58', 'Blank-59', 'Blank-60'],\n",
      "      dtype='object', length=461)\n",
      "1003_region_0.h5ad\n",
      "AnnData object with n_obs × n_vars = 369399 × 461\n",
      "    obs: 'fov', 'volume', 'center_x', 'center_y', 'min_x', 'min_y', 'max_x', 'max_y', 'barcodeCount'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid1/YiDingcheng/miniforge3/envs/pyg/lib/python3.10/site-packages/anndata/_core/aligned_df.py:68: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ACTA2', 'ACTG2', 'ADAM12', 'ADAM28', 'ADGRE5', 'ADH1B', 'CCL21',\n",
      "       'AIM2', 'ANKRD55', 'AREG',\n",
      "       ...\n",
      "       'Blank-51', 'Blank-52', 'Blank-53', 'Blank-54', 'Blank-55', 'Blank-56',\n",
      "       'Blank-57', 'Blank-58', 'Blank-59', 'Blank-60'],\n",
      "      dtype='object', length=461)\n",
      "1012_region_0.h5ad\n",
      "AnnData object with n_obs × n_vars = 283525 × 461\n",
      "    obs: 'fov', 'volume', 'center_x', 'center_y', 'min_x', 'min_y', 'max_x', 'max_y', 'barcodeCount'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid1/YiDingcheng/miniforge3/envs/pyg/lib/python3.10/site-packages/anndata/_core/aligned_df.py:68: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ACTA2', 'ACTG2', 'ADAM12', 'ADAM28', 'ADGRE5', 'ADH1B', 'CCL21',\n",
      "       'AIM2', 'ANKRD55', 'AREG',\n",
      "       ...\n",
      "       'Blank-51', 'Blank-52', 'Blank-53', 'Blank-54', 'Blank-55', 'Blank-56',\n",
      "       'Blank-57', 'Blank-58', 'Blank-59', 'Blank-60'],\n",
      "      dtype='object', length=461)\n",
      "1012_region_1.h5ad\n",
      "AnnData object with n_obs × n_vars = 131426 × 461\n",
      "    obs: 'fov', 'volume', 'center_x', 'center_y', 'min_x', 'min_y', 'max_x', 'max_y', 'barcodeCount'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid1/YiDingcheng/miniforge3/envs/pyg/lib/python3.10/site-packages/anndata/_core/aligned_df.py:68: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ACTA2', 'ACTG2', 'ADAM12', 'ADAM28', 'ADGRE5', 'ADH1B', 'CCL21',\n",
      "       'AIM2', 'ANKRD55', 'AREG',\n",
      "       ...\n",
      "       'Blank-51', 'Blank-52', 'Blank-53', 'Blank-54', 'Blank-55', 'Blank-56',\n",
      "       'Blank-57', 'Blank-58', 'Blank-59', 'Blank-60'],\n",
      "      dtype='object', length=461)\n",
      "1014_region_0.h5ad\n",
      "AnnData object with n_obs × n_vars = 207552 × 461\n",
      "    obs: 'fov', 'volume', 'center_x', 'center_y', 'min_x', 'min_y', 'max_x', 'max_y', 'barcodeCount'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid1/YiDingcheng/miniforge3/envs/pyg/lib/python3.10/site-packages/anndata/_core/aligned_df.py:68: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ACTA2', 'ACTG2', 'ADAM12', 'ADAM28', 'ADGRE5', 'ADH1B', 'CCL21',\n",
      "       'AIM2', 'ANKRD55', 'AREG',\n",
      "       ...\n",
      "       'Blank-51', 'Blank-52', 'Blank-53', 'Blank-54', 'Blank-55', 'Blank-56',\n",
      "       'Blank-57', 'Blank-58', 'Blank-59', 'Blank-60'],\n",
      "      dtype='object', length=461)\n",
      "1014_region_1.h5ad\n",
      "AnnData object with n_obs × n_vars = 25449 × 461\n",
      "    obs: 'fov', 'volume', 'center_x', 'center_y', 'min_x', 'min_y', 'max_x', 'max_y', 'barcodeCount'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid1/YiDingcheng/miniforge3/envs/pyg/lib/python3.10/site-packages/anndata/_core/aligned_df.py:68: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ACTA2', 'ACTG2', 'ADAM12', 'ADAM28', 'ADGRE5', 'ADH1B', 'CCL21',\n",
      "       'AIM2', 'ANKRD55', 'AREG',\n",
      "       ...\n",
      "       'Blank-51', 'Blank-52', 'Blank-53', 'Blank-54', 'Blank-55', 'Blank-56',\n",
      "       'Blank-57', 'Blank-58', 'Blank-59', 'Blank-60'],\n",
      "      dtype='object', length=461)\n",
      "1017_region_0.h5ad\n",
      "AnnData object with n_obs × n_vars = 61404 × 461\n",
      "    obs: 'fov', 'volume', 'center_x', 'center_y', 'min_x', 'min_y', 'max_x', 'max_y', 'barcodeCount'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid1/YiDingcheng/miniforge3/envs/pyg/lib/python3.10/site-packages/anndata/_core/aligned_df.py:68: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ACTA2', 'ACTG2', 'ADAM12', 'ADAM28', 'ADGRE5', 'ADH1B', 'CCL21',\n",
      "       'AIM2', 'ANKRD55', 'AREG',\n",
      "       ...\n",
      "       'Blank-51', 'Blank-52', 'Blank-53', 'Blank-54', 'Blank-55', 'Blank-56',\n",
      "       'Blank-57', 'Blank-58', 'Blank-59', 'Blank-60'],\n",
      "      dtype='object', length=461)\n",
      "1029_region_0.h5ad\n",
      "AnnData object with n_obs × n_vars = 120434 × 461\n",
      "    obs: 'fov', 'volume', 'center_x', 'center_y', 'min_x', 'min_y', 'max_x', 'max_y', 'barcodeCount'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid1/YiDingcheng/miniforge3/envs/pyg/lib/python3.10/site-packages/anndata/_core/aligned_df.py:68: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ACTA2', 'ACTG2', 'ADAM12', 'ADAM28', 'ADGRE5', 'ADH1B', 'CCL21',\n",
      "       'AIM2', 'ANKRD55', 'AREG',\n",
      "       ...\n",
      "       'Blank-51', 'Blank-52', 'Blank-53', 'Blank-54', 'Blank-55', 'Blank-56',\n",
      "       'Blank-57', 'Blank-58', 'Blank-59', 'Blank-60'],\n",
      "      dtype='object', length=461)\n",
      "122_region_0.h5ad\n",
      "AnnData object with n_obs × n_vars = 91860 × 461\n",
      "    obs: 'fov', 'volume', 'center_x', 'center_y', 'min_x', 'min_y', 'max_x', 'max_y', 'barcodeCount'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid1/YiDingcheng/miniforge3/envs/pyg/lib/python3.10/site-packages/anndata/_core/aligned_df.py:68: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ACTA2', 'ACTG2', 'ADAM12', 'ADAM28', 'ADGRE5', 'ADH1B', 'CCL21',\n",
      "       'AIM2', 'ANKRD55', 'AREG',\n",
      "       ...\n",
      "       'Blank-51', 'Blank-52', 'Blank-53', 'Blank-54', 'Blank-55', 'Blank-56',\n",
      "       'Blank-57', 'Blank-58', 'Blank-59', 'Blank-60'],\n",
      "      dtype='object', length=461)\n",
      "122_region_1.h5ad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid1/YiDingcheng/miniforge3/envs/pyg/lib/python3.10/site-packages/anndata/_core/aligned_df.py:68: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 151647 × 461\n",
      "    obs: 'fov', 'volume', 'center_x', 'center_y', 'min_x', 'min_y', 'max_x', 'max_y', 'barcodeCount'\n",
      "Index(['ACTA2', 'ACTG2', 'ADAM12', 'ADAM28', 'ADGRE5', 'ADH1B', 'CCL21',\n",
      "       'AIM2', 'ANKRD55', 'AREG',\n",
      "       ...\n",
      "       'Blank-51', 'Blank-52', 'Blank-53', 'Blank-54', 'Blank-55', 'Blank-56',\n",
      "       'Blank-57', 'Blank-58', 'Blank-59', 'Blank-60'],\n",
      "      dtype='object', length=461)\n",
      "63_region_0.h5ad\n",
      "AnnData object with n_obs × n_vars = 228679 × 461\n",
      "    obs: 'fov', 'volume', 'center_x', 'center_y', 'min_x', 'min_y', 'max_x', 'max_y', 'barcodeCount'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid1/YiDingcheng/miniforge3/envs/pyg/lib/python3.10/site-packages/anndata/_core/aligned_df.py:68: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    }
   ],
   "source": [
    "regex = re.compile(r'(\\d+)_region_(\\d+)')\n",
    "# 读取数据\n",
    "pseudo_bulk = {}\n",
    "for i in range(len(csv_files)):\n",
    "    exp_matrix = pd.read_csv(os.path.join(path, csv_files[i]), index_col=0)\n",
    "    if i == 0:\n",
    "       gene_features = exp_matrix.columns \n",
    "    exp_matrix = exp_matrix.loc[:, gene_features]\n",
    "    print(exp_matrix.columns)\n",
    "    metadata = pd.read_csv(os.path.join(path, metadata_files[i]), index_col=0)\n",
    "    match = regex.search(csv_files[i])\n",
    "    if match:\n",
    "        adata_filename = f'{match.group(1)}_region_{match.group(2)}.h5ad'\n",
    "        print(adata_filename)\n",
    "    adata = anndata.AnnData(X=exp_matrix.values, obs=metadata)\n",
    "    print(adata)\n",
    "    pseudo_bulk[f'{match.group(1)}_{match.group(2)}'] = adata.X.sum(axis=0)\n",
    "    adata.write_h5ad(os.path.join(path, adata_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1003_0</th>\n",
       "      <th>1012_0</th>\n",
       "      <th>1012_1</th>\n",
       "      <th>1014_0</th>\n",
       "      <th>1014_1</th>\n",
       "      <th>1017_0</th>\n",
       "      <th>1029_0</th>\n",
       "      <th>122_0</th>\n",
       "      <th>122_1</th>\n",
       "      <th>63_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACTA2</th>\n",
       "      <td>270227.0</td>\n",
       "      <td>434886.0</td>\n",
       "      <td>201380.0</td>\n",
       "      <td>59374.0</td>\n",
       "      <td>9884.0</td>\n",
       "      <td>32705.0</td>\n",
       "      <td>106966.0</td>\n",
       "      <td>38842.0</td>\n",
       "      <td>22886.0</td>\n",
       "      <td>13156.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACTG2</th>\n",
       "      <td>22833.0</td>\n",
       "      <td>17338.0</td>\n",
       "      <td>5980.0</td>\n",
       "      <td>3665.0</td>\n",
       "      <td>554.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>5193.0</td>\n",
       "      <td>3040.0</td>\n",
       "      <td>3080.0</td>\n",
       "      <td>1697.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADAM12</th>\n",
       "      <td>16661.0</td>\n",
       "      <td>20374.0</td>\n",
       "      <td>3441.0</td>\n",
       "      <td>1697.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>3404.0</td>\n",
       "      <td>3379.0</td>\n",
       "      <td>5146.0</td>\n",
       "      <td>6441.0</td>\n",
       "      <td>2016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADAM28</th>\n",
       "      <td>35283.0</td>\n",
       "      <td>13956.0</td>\n",
       "      <td>12717.0</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1554.0</td>\n",
       "      <td>3660.0</td>\n",
       "      <td>4583.0</td>\n",
       "      <td>3822.0</td>\n",
       "      <td>1905.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADGRE5</th>\n",
       "      <td>402208.0</td>\n",
       "      <td>346434.0</td>\n",
       "      <td>87069.0</td>\n",
       "      <td>41693.0</td>\n",
       "      <td>7982.0</td>\n",
       "      <td>42169.0</td>\n",
       "      <td>47220.0</td>\n",
       "      <td>60694.0</td>\n",
       "      <td>35784.0</td>\n",
       "      <td>29150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blank-56</th>\n",
       "      <td>5819.0</td>\n",
       "      <td>2860.0</td>\n",
       "      <td>1556.0</td>\n",
       "      <td>388.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>652.0</td>\n",
       "      <td>279.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blank-57</th>\n",
       "      <td>5225.0</td>\n",
       "      <td>3626.0</td>\n",
       "      <td>1504.0</td>\n",
       "      <td>408.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>607.0</td>\n",
       "      <td>736.0</td>\n",
       "      <td>625.0</td>\n",
       "      <td>489.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blank-58</th>\n",
       "      <td>5817.0</td>\n",
       "      <td>2875.0</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>427.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>797.0</td>\n",
       "      <td>1120.0</td>\n",
       "      <td>821.0</td>\n",
       "      <td>419.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blank-59</th>\n",
       "      <td>17939.0</td>\n",
       "      <td>7644.0</td>\n",
       "      <td>3699.0</td>\n",
       "      <td>888.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>538.0</td>\n",
       "      <td>1721.0</td>\n",
       "      <td>726.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>675.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blank-60</th>\n",
       "      <td>10680.0</td>\n",
       "      <td>3785.0</td>\n",
       "      <td>1938.0</td>\n",
       "      <td>483.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>509.0</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>669.0</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>461 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1003_0    1012_0    1012_1   1014_0  1014_1   1017_0    1029_0  \\\n",
       "ACTA2     270227.0  434886.0  201380.0  59374.0  9884.0  32705.0  106966.0   \n",
       "ACTG2      22833.0   17338.0    5980.0   3665.0   554.0   1138.0    5193.0   \n",
       "ADAM12     16661.0   20374.0    3441.0   1697.0   399.0   3404.0    3379.0   \n",
       "ADAM28     35283.0   13956.0   12717.0   1170.0    88.0   1554.0    3660.0   \n",
       "ADGRE5    402208.0  346434.0   87069.0  41693.0  7982.0  42169.0   47220.0   \n",
       "...            ...       ...       ...      ...     ...      ...       ...   \n",
       "Blank-56    5819.0    2860.0    1556.0    388.0    52.0    214.0     555.0   \n",
       "Blank-57    5225.0    3626.0    1504.0    408.0    58.0    502.0     607.0   \n",
       "Blank-58    5817.0    2875.0    1964.0    427.0    54.0    253.0     797.0   \n",
       "Blank-59   17939.0    7644.0    3699.0    888.0    75.0    538.0    1721.0   \n",
       "Blank-60   10680.0    3785.0    1938.0    483.0    68.0    509.0    1065.0   \n",
       "\n",
       "            122_0    122_1     63_0  \n",
       "ACTA2     38842.0  22886.0  13156.0  \n",
       "ACTG2      3040.0   3080.0   1697.0  \n",
       "ADAM12     5146.0   6441.0   2016.0  \n",
       "ADAM28     4583.0   3822.0   1905.0  \n",
       "ADGRE5    60694.0  35784.0  29150.0  \n",
       "...           ...      ...      ...  \n",
       "Blank-56    520.0    652.0    279.0  \n",
       "Blank-57    736.0    625.0    489.0  \n",
       "Blank-58   1120.0    821.0    419.0  \n",
       "Blank-59    726.0    594.0    675.0  \n",
       "Blank-60    711.0    669.0    399.0  \n",
       "\n",
       "[461 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_bulk = pd.DataFrame(pseudo_bulk)\n",
    "pseudo_bulk.index = exp_matrix.columns\n",
    "pseudo_bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_bulk.to_csv(os.path.join(path, 'pseudo_bulk.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_data = pd.read_table('../data/TCGA/TCGA-COAD.htseq_counts.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['submitter_id.samples',\n",
       "       'adjacent_hepatic_tissue_inflammation_extent_type',\n",
       "       'age_at_initial_pathologic_diagnosis', 'albumin_result_lower_limit',\n",
       "       'albumin_result_specified_value', 'albumin_result_upper_limit',\n",
       "       'batch_number', 'bcr', 'bcr_followup_barcode', 'bcr_followup_uuid',\n",
       "       ...\n",
       "       'days_to_collection.samples', 'days_to_sample_procurement.samples',\n",
       "       'initial_weight.samples', 'is_ffpe.samples', 'oct_embedded.samples',\n",
       "       'preservation_method.samples', 'sample_type.samples',\n",
       "       'sample_type_id.samples', 'state.samples', 'tissue_type.samples'],\n",
       "      dtype='object', length=119)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinical = pd.read_table('../data/TCGA/TCGA-LIHC.GDC_phenotype.tsv')\n",
    "# clinical = pd.read_table('../data/TCGA/TCGA-COAD.GDC_phenotype.tsv')\n",
    "clinical.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expression_data = pd.read_table('../data/Cleaned_data/Colon/TCGA-COAD.htseq_counts_clean.tsv', index_col=0)\n",
    "expression_data = pd.read_csv('../data/Cleaned_data/Liver/TCGA-LIHC.htseq_counts_clean.csv', index_col=0)\n",
    "# expression_data = pd.read_table('../data/TCGA/TCGA-LIHC_TPM_clean.tsv', index_col=0)\n",
    "# label = pd.read_csv('../data/Cleaned_data/Colon/TCGA-COAD.survival_clean.csv')\n",
    "label = pd.read_csv('../data/Cleaned_data/Liver/TCGA-LIHC.survival_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OS</th>\n",
       "      <th>X_PATIENT</th>\n",
       "      <th>OS.time</th>\n",
       "      <th>barcode</th>\n",
       "      <th>median_surv</th>\n",
       "      <th>sample_type</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>batch_number</th>\n",
       "      <th>tumor_stage.diagnoses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>TCGA-FV-A495</td>\n",
       "      <td>1</td>\n",
       "      <td>TCGA.FV.A495.01A</td>\n",
       "      <td>short</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>TCGA.FV.A495.01A</td>\n",
       "      <td>275.62.0</td>\n",
       "      <td>stage ii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>TCGA-ED-A7PZ</td>\n",
       "      <td>6</td>\n",
       "      <td>TCGA.ED.A7PZ.01A</td>\n",
       "      <td>short</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>TCGA.ED.A7PZ.01A</td>\n",
       "      <td>345.53.0</td>\n",
       "      <td>stage ii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>TCGA-ED-A97K</td>\n",
       "      <td>6</td>\n",
       "      <td>TCGA.ED.A97K.01A</td>\n",
       "      <td>short</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>TCGA.ED.A97K.01A</td>\n",
       "      <td>399.48.0</td>\n",
       "      <td>stage iiia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>TCGA-ED-A7PX</td>\n",
       "      <td>6</td>\n",
       "      <td>TCGA.ED.A7PX.01A</td>\n",
       "      <td>short</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>TCGA.ED.A7PX.01A</td>\n",
       "      <td>365.54.0</td>\n",
       "      <td>stage ii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>TCGA-BC-A3KF</td>\n",
       "      <td>8</td>\n",
       "      <td>TCGA.BC.A3KF.01A</td>\n",
       "      <td>short</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>TCGA.BC.A3KF.01A</td>\n",
       "      <td>203.73.0</td>\n",
       "      <td>stage i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>0</td>\n",
       "      <td>TCGA-DD-A4NP</td>\n",
       "      <td>3308</td>\n",
       "      <td>TCGA.DD.A4NP.01A</td>\n",
       "      <td>long</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>TCGA.DD.A4NP.01A</td>\n",
       "      <td>303.59.0</td>\n",
       "      <td>stage i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>0</td>\n",
       "      <td>TCGA-DD-A118</td>\n",
       "      <td>3437</td>\n",
       "      <td>TCGA.DD.A118.11A</td>\n",
       "      <td>long</td>\n",
       "      <td>Normal</td>\n",
       "      <td>TCGA.DD.A118.11A</td>\n",
       "      <td>100.78.0</td>\n",
       "      <td>stage ii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>0</td>\n",
       "      <td>TCGA-DD-A118</td>\n",
       "      <td>3437</td>\n",
       "      <td>TCGA.DD.A118.01A</td>\n",
       "      <td>long</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>TCGA.DD.A118.01A</td>\n",
       "      <td>100.78.0</td>\n",
       "      <td>stage ii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>0</td>\n",
       "      <td>TCGA-DD-A73G</td>\n",
       "      <td>3478</td>\n",
       "      <td>TCGA.DD.A73G.01A</td>\n",
       "      <td>long</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>TCGA.DD.A73G.01A</td>\n",
       "      <td>327.54.0</td>\n",
       "      <td>stage i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>0</td>\n",
       "      <td>TCGA-2Y-A9H0</td>\n",
       "      <td>3675</td>\n",
       "      <td>TCGA.2Y.A9H0.01A</td>\n",
       "      <td>long</td>\n",
       "      <td>Tumor</td>\n",
       "      <td>TCGA.2Y.A9H0.01A</td>\n",
       "      <td>399.48.0</td>\n",
       "      <td>stage iiia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     OS     X_PATIENT  OS.time           barcode median_surv sample_type  \\\n",
       "0     0  TCGA-FV-A495        1  TCGA.FV.A495.01A       short       Tumor   \n",
       "1     0  TCGA-ED-A7PZ        6  TCGA.ED.A7PZ.01A       short       Tumor   \n",
       "2     0  TCGA-ED-A97K        6  TCGA.ED.A97K.01A       short       Tumor   \n",
       "3     0  TCGA-ED-A7PX        6  TCGA.ED.A7PX.01A       short       Tumor   \n",
       "4     0  TCGA-BC-A3KF        8  TCGA.BC.A3KF.01A       short       Tumor   \n",
       "..   ..           ...      ...               ...         ...         ...   \n",
       "413   0  TCGA-DD-A4NP     3308  TCGA.DD.A4NP.01A        long       Tumor   \n",
       "414   0  TCGA-DD-A118     3437  TCGA.DD.A118.11A        long      Normal   \n",
       "415   0  TCGA-DD-A118     3437  TCGA.DD.A118.01A        long       Tumor   \n",
       "416   0  TCGA-DD-A73G     3478  TCGA.DD.A73G.01A        long       Tumor   \n",
       "417   0  TCGA-2Y-A9H0     3675  TCGA.2Y.A9H0.01A        long       Tumor   \n",
       "\n",
       "            sample_id batch_number tumor_stage.diagnoses  \n",
       "0    TCGA.FV.A495.01A     275.62.0              stage ii  \n",
       "1    TCGA.ED.A7PZ.01A     345.53.0              stage ii  \n",
       "2    TCGA.ED.A97K.01A     399.48.0            stage iiia  \n",
       "3    TCGA.ED.A7PX.01A     365.54.0              stage ii  \n",
       "4    TCGA.BC.A3KF.01A     203.73.0               stage i  \n",
       "..                ...          ...                   ...  \n",
       "413  TCGA.DD.A4NP.01A     303.59.0               stage i  \n",
       "414  TCGA.DD.A118.11A     100.78.0              stage ii  \n",
       "415  TCGA.DD.A118.01A     100.78.0              stage ii  \n",
       "416  TCGA.DD.A73G.01A     327.54.0               stage i  \n",
       "417  TCGA.2Y.A9H0.01A     399.48.0            stage iiia  \n",
       "\n",
       "[418 rows x 9 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clinical['sample_id'] = clinical['submitter_id.samples'].str.replace('-', '.')\n",
    "label = label.merge(clinical[['sample_id', 'batch_number', 'tumor_stage.diagnoses']], left_on='barcode', right_on='sample_id')\n",
    "# label = label[label['sample_type'] == 'Tumor']\n",
    "label\n",
    "# label.to_csv('../data/Cleaned_data/Liver/TCGA-LIHC.survival_clean_tumor.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "early_stage  tumor_stage_label\n",
       "True         1                    172\n",
       "             2                     85\n",
       "False        3                     83\n",
       "True         0                     50\n",
       "False        4                      4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_stage(x):\n",
    "    if x['sample_type'] == 'Normal':\n",
    "        return 0\n",
    "    elif x['tumor_stage.diagnoses'] in ['not reported']:\n",
    "        return pd.NA\n",
    "    else:\n",
    "        if 'stage iii' in x['tumor_stage.diagnoses'].lower():\n",
    "            return 3\n",
    "        elif 'stage ii' in x['tumor_stage.diagnoses'].lower():\n",
    "            return 2\n",
    "        elif 'stage iv' in x['tumor_stage.diagnoses'].lower():\n",
    "            return 4\n",
    "        elif 'stage i' in x['tumor_stage.diagnoses'].lower():\n",
    "            return 1\n",
    "        return pd.NA\n",
    "\n",
    "\n",
    "label['tumor_stage_label'] = label.apply(convert_stage, axis=1)\n",
    "label['early_stage'] = label['tumor_stage_label'] <= 2\n",
    "label = label.dropna(subset=['tumor_stage_label'])\n",
    "label = label.dropna(subset=['sample_type'])\n",
    "label.value_counts(['early_stage', 'tumor_stage_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_data = np.log1p(expression_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ACTA2</th>\n",
       "      <th>ACTG2</th>\n",
       "      <th>ADAM12</th>\n",
       "      <th>ADAM28</th>\n",
       "      <th>ADGRE5</th>\n",
       "      <th>ADH1B</th>\n",
       "      <th>AIM2</th>\n",
       "      <th>ANKRD55</th>\n",
       "      <th>AREG</th>\n",
       "      <th>ASPN</th>\n",
       "      <th>...</th>\n",
       "      <th>VPS37B</th>\n",
       "      <th>VWF</th>\n",
       "      <th>WDFY4</th>\n",
       "      <th>XBP1</th>\n",
       "      <th>XCR1</th>\n",
       "      <th>YPEL5</th>\n",
       "      <th>ZBTB16</th>\n",
       "      <th>ZC3HAV1</th>\n",
       "      <th>ZFP36L1</th>\n",
       "      <th>ZNF331</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCGA.FV.A495.01A</th>\n",
       "      <td>6094</td>\n",
       "      <td>96</td>\n",
       "      <td>65</td>\n",
       "      <td>69</td>\n",
       "      <td>1726</td>\n",
       "      <td>21991</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>42</td>\n",
       "      <td>1500</td>\n",
       "      <td>...</td>\n",
       "      <td>622</td>\n",
       "      <td>3707</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1774</td>\n",
       "      <td>623</td>\n",
       "      <td>777</td>\n",
       "      <td>6809</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA.ED.A7PZ.01A</th>\n",
       "      <td>8413</td>\n",
       "      <td>1476</td>\n",
       "      <td>55</td>\n",
       "      <td>11</td>\n",
       "      <td>4548</td>\n",
       "      <td>3495</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>218</td>\n",
       "      <td>345</td>\n",
       "      <td>...</td>\n",
       "      <td>675</td>\n",
       "      <td>3256</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3286</td>\n",
       "      <td>13</td>\n",
       "      <td>858</td>\n",
       "      <td>2832</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA.ED.A97K.01A</th>\n",
       "      <td>6415</td>\n",
       "      <td>109</td>\n",
       "      <td>239</td>\n",
       "      <td>5451</td>\n",
       "      <td>3765</td>\n",
       "      <td>27048</td>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>252</td>\n",
       "      <td>1551</td>\n",
       "      <td>...</td>\n",
       "      <td>2616</td>\n",
       "      <td>2556</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>6159</td>\n",
       "      <td>81</td>\n",
       "      <td>2871</td>\n",
       "      <td>15971</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA.ED.A7PX.01A</th>\n",
       "      <td>18077</td>\n",
       "      <td>1569</td>\n",
       "      <td>598</td>\n",
       "      <td>155</td>\n",
       "      <td>2888</td>\n",
       "      <td>540</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>2270</td>\n",
       "      <td>...</td>\n",
       "      <td>1682</td>\n",
       "      <td>3415</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>5204</td>\n",
       "      <td>23</td>\n",
       "      <td>1123</td>\n",
       "      <td>8968</td>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA.BC.A3KF.01A</th>\n",
       "      <td>4487</td>\n",
       "      <td>619</td>\n",
       "      <td>54</td>\n",
       "      <td>47</td>\n",
       "      <td>554</td>\n",
       "      <td>17776</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>201</td>\n",
       "      <td>...</td>\n",
       "      <td>621</td>\n",
       "      <td>3903</td>\n",
       "      <td>104</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>7001</td>\n",
       "      <td>427</td>\n",
       "      <td>2236</td>\n",
       "      <td>7918</td>\n",
       "      <td>1211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA.DD.A4NP.01A</th>\n",
       "      <td>5408</td>\n",
       "      <td>314</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>643</td>\n",
       "      <td>423517</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>515</td>\n",
       "      <td>...</td>\n",
       "      <td>596</td>\n",
       "      <td>4764</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5351</td>\n",
       "      <td>422</td>\n",
       "      <td>1788</td>\n",
       "      <td>9308</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA.DD.A118.11A</th>\n",
       "      <td>550</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>475</td>\n",
       "      <td>173907</td>\n",
       "      <td>24</td>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>299</td>\n",
       "      <td>...</td>\n",
       "      <td>376</td>\n",
       "      <td>192</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2132</td>\n",
       "      <td>307</td>\n",
       "      <td>615</td>\n",
       "      <td>4990</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA.DD.A118.01A</th>\n",
       "      <td>10327</td>\n",
       "      <td>176</td>\n",
       "      <td>146</td>\n",
       "      <td>48</td>\n",
       "      <td>927</td>\n",
       "      <td>1466</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>1141</td>\n",
       "      <td>...</td>\n",
       "      <td>388</td>\n",
       "      <td>8270</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>7931</td>\n",
       "      <td>188</td>\n",
       "      <td>1081</td>\n",
       "      <td>6480</td>\n",
       "      <td>1327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA.DD.A73G.01A</th>\n",
       "      <td>4369</td>\n",
       "      <td>464</td>\n",
       "      <td>13</td>\n",
       "      <td>26</td>\n",
       "      <td>1141</td>\n",
       "      <td>5949</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>418</td>\n",
       "      <td>...</td>\n",
       "      <td>723</td>\n",
       "      <td>9429</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2410</td>\n",
       "      <td>29</td>\n",
       "      <td>694</td>\n",
       "      <td>3178</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCGA.2Y.A9H0.01A</th>\n",
       "      <td>2181</td>\n",
       "      <td>224</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>1331</td>\n",
       "      <td>8045</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>553</td>\n",
       "      <td>2695</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>2817</td>\n",
       "      <td>119</td>\n",
       "      <td>1996</td>\n",
       "      <td>4206</td>\n",
       "      <td>924</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>394 rows × 398 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ACTA2  ACTG2  ADAM12  ADAM28  ADGRE5   ADH1B  AIM2  ANKRD55  \\\n",
       "TCGA.FV.A495.01A   6094     96      65      69    1726   21991    16       19   \n",
       "TCGA.ED.A7PZ.01A   8413   1476      55      11    4548    3495     3       10   \n",
       "TCGA.ED.A97K.01A   6415    109     239    5451    3765   27048    40       45   \n",
       "TCGA.ED.A7PX.01A  18077   1569     598     155    2888     540    13       10   \n",
       "TCGA.BC.A3KF.01A   4487    619      54      47     554   17776     1       36   \n",
       "...                 ...    ...     ...     ...     ...     ...   ...      ...   \n",
       "TCGA.DD.A4NP.01A   5408    314      11      23     643  423517     5       25   \n",
       "TCGA.DD.A118.11A    550     12      11      12     475  173907    24       72   \n",
       "TCGA.DD.A118.01A  10327    176     146      48     927    1466     7        3   \n",
       "TCGA.DD.A73G.01A   4369    464      13      26    1141    5949     3       23   \n",
       "TCGA.2Y.A9H0.01A   2181    224      23      20    1331    8045    43        1   \n",
       "\n",
       "                  AREG  ASPN  ...  VPS37B   VWF  WDFY4  XBP1  XCR1  YPEL5  \\\n",
       "TCGA.FV.A495.01A    42  1500  ...     622  3707    153     0    22   1774   \n",
       "TCGA.ED.A7PZ.01A   218   345  ...     675  3256     25     0     1   3286   \n",
       "TCGA.ED.A97K.01A   252  1551  ...    2616  2556    294     0    13   6159   \n",
       "TCGA.ED.A7PX.01A    50  2270  ...    1682  3415    180     0    15   5204   \n",
       "TCGA.BC.A3KF.01A     7   201  ...     621  3903    104     0    22   7001   \n",
       "...                ...   ...  ...     ...   ...    ...   ...   ...    ...   \n",
       "TCGA.DD.A4NP.01A     7   515  ...     596  4764     85     0     7   5351   \n",
       "TCGA.DD.A118.11A     5   299  ...     376   192     73     0    15   2132   \n",
       "TCGA.DD.A118.01A    23  1141  ...     388  8270    160     0    13   7931   \n",
       "TCGA.DD.A73G.01A     7   418  ...     723  9429     65     0     1   2410   \n",
       "TCGA.2Y.A9H0.01A    51    89  ...     553  2695     95     0    10   2817   \n",
       "\n",
       "                  ZBTB16  ZC3HAV1  ZFP36L1  ZNF331  \n",
       "TCGA.FV.A495.01A     623      777     6809     349  \n",
       "TCGA.ED.A7PZ.01A      13      858     2832    1024  \n",
       "TCGA.ED.A97K.01A      81     2871    15971     176  \n",
       "TCGA.ED.A7PX.01A      23     1123     8968     430  \n",
       "TCGA.BC.A3KF.01A     427     2236     7918    1211  \n",
       "...                  ...      ...      ...     ...  \n",
       "TCGA.DD.A4NP.01A     422     1788     9308      94  \n",
       "TCGA.DD.A118.11A     307      615     4990     432  \n",
       "TCGA.DD.A118.01A     188     1081     6480    1327  \n",
       "TCGA.DD.A73G.01A      29      694     3178      79  \n",
       "TCGA.2Y.A9H0.01A     119     1996     4206     924  \n",
       "\n",
       "[394 rows x 398 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expression_data=expression_data.transpose()\n",
    "expression_data.index = expression_data.index.str.replace('-', '.')\n",
    "expression_data=expression_data[expression_data.index.isin(label['barcode'])]\n",
    "expression_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "early_stage\n",
       "True     307\n",
       "False     87\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.value_counts('early_stage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/DingchengYi/miniforge3/envs/pyg/lib/python3.11/site-packages/scanpy/preprocessing/_highly_variable_genes.py:412: UserWarning: `n_top_genes` > number of normalized dispersions, returning all genes with normalized dispersions.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "adata = sc.AnnData(expression_data)\n",
    "\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "sc.pp.highly_variable_genes(adata, n_top_genes=1000)\n",
    "expression_data = expression_data[expression_data.columns[adata.var.highly_variable.values]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227     True\n",
      "54      True\n",
      "21      True\n",
      "396     True\n",
      "62     False\n",
      "       ...  \n",
      "384     True\n",
      "287     True\n",
      "382     True\n",
      "378     True\n",
      "144     True\n",
      "Name: early_stage, Length: 394, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(label['early_stage'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1123)\n",
    "label['tumor_stage_label'] = label.iloc[np.random.permutation(len(label)), :]['tumor_stage_label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "label['median_surv'] = label['OS.time'] < label['OS.time'].median()\n",
    "\n",
    "train_exp, test_exp, train_label, test_label = train_test_split(expression_data, label, test_size=0.2, random_state=42, stratify=label['early_stage'])\n",
    "train_exp.to_csv('../data/Cleaned_data/Liver/train_exp.csv')\n",
    "test_exp.to_csv('../data/Cleaned_data/Liver/test_exp.csv')\n",
    "train_label.to_csv('../data/Cleaned_data/Liver/train_label.csv')\n",
    "test_label.to_csv('../data/Cleaned_data/Liver/test_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "315\n",
      "79\n",
      "Random 399 max acc: 0.4556962251663208\n",
      "1\n",
      "315\n",
      "79\n",
      "Random 399 max acc: 0.5696202516555786\n",
      "2\n",
      "315\n",
      "79\n",
      "Random 399 max acc: 0.4683544337749481\n",
      "3\n",
      "315\n",
      "79\n",
      "Random 399 max acc: 0.4556962251663208\n",
      "4\n",
      "315\n",
      "79\n",
      "Random 399 max acc: 0.4303797483444214\n",
      "5\n",
      "315\n",
      "79\n",
      "Random 399 max acc: 0.4556962251663208\n",
      "6\n",
      "315\n",
      "79\n",
      "Random 399 max acc: 0.49367091059684753\n",
      "7\n",
      "315\n",
      "79\n",
      "Random 399 max acc: 0.4303797483444214\n",
      "8\n",
      "315\n",
      "79\n",
      "Random 399 max acc: 0.41772153973579407\n",
      "9\n",
      "315\n",
      "79\n",
      "Random 399 max acc: 0.41772153973579407\n",
      "10\n",
      "315\n",
      "79\n",
      "Random 399 max acc: 0.4556962251663208\n",
      "11\n",
      "315\n",
      "79\n",
      "Random 399 max acc: 0.5316455960273743\n",
      "12\n",
      "315\n",
      "79\n",
      "Random 399 max acc: 0.5316455960273743\n",
      "13\n",
      "315\n",
      "79\n",
      "Random 399 max acc: 0.4683544337749481\n",
      "14\n",
      "315\n",
      "79\n",
      "Random 399 max acc: 0.41772153973579407\n",
      "15\n",
      "315\n",
      "79\n",
      "Random 399 max acc: 0.4683544337749481\n",
      "16\n",
      "315\n",
      "79\n",
      "Random 399 max acc: 0.40506330132484436\n",
      "17\n",
      "315\n",
      "79\n",
      "Random 399 max acc: 0.5063291192054749\n",
      "18\n",
      "315\n",
      "79\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 66\u001b[0m\n\u001b[1;32m     64\u001b[0m variance \u001b[38;5;241m=\u001b[39m variance\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     65\u001b[0m batch_index \u001b[38;5;241m=\u001b[39m batch_index\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 66\u001b[0m recon_loss, kl_z, kl_l, classification_loss, probs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m mean_recon_loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(recon_loss)\n\u001b[1;32m     68\u001b[0m mean_kl_z \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(kl_z)\n",
      "File \u001b[0;32m~/miniforge3/envs/pyg/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pyg/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/BulkPheno/src/model.py:284\u001b[0m, in \u001b[0;36mBulkVAE.forward\u001b[0;34m(self, x, local_l_mean, local_l_var, batch_index, y)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    x: torch.Tensor, shape (batch_size, n_input)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;124;03m    y: torch.Tensor, shape (batch_size, n_labels), this is the label for each sample\u001b[39;00m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    283\u001b[0m is_labelled \u001b[38;5;241m=\u001b[39m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 284\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m dispersion \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdispersion\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    286\u001b[0m rate \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrate\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/BulkPheno/src/model.py:247\u001b[0m, in \u001b[0;36mBulkVAE.inference\u001b[0;34m(self, x, batch_index, y, n_samples)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_norm:\n\u001b[1;32m    245\u001b[0m     x_ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlog1p(x)\n\u001b[0;32m--> 247\u001b[0m z, qz_m, qz_v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mz_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m l, ql_m, ql_v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml_encoder(x_)\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/pyg/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pyg/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/BulkPheno/src/model.py:120\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, x, *cat_list)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39mcat_list):\n\u001b[0;32m--> 120\u001b[0m     q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcat_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     mu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean_encoder(q)\n\u001b[1;32m    122\u001b[0m     var \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvar_encoder(q)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-4\u001b[39m\n",
      "File \u001b[0;32m~/miniforge3/envs/pyg/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/pyg/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/BulkPheno/src/model.py:91\u001b[0m, in \u001b[0;36mFCLayers.forward\u001b[0;34m(self, x, *cat_list)\u001b[0m\n\u001b[1;32m     89\u001b[0m                         one_hot_cat_list_layer \u001b[38;5;241m=\u001b[39m one_hot_cat_list\n\u001b[1;32m     90\u001b[0m                     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x, \u001b[38;5;241m*\u001b[39mone_hot_cat_list_layer), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 91\u001b[0m                 x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from model import BulkVAE\n",
    "from dataset import TCGADataset, collate_fn\n",
    "from trainer import VAETrainer\n",
    "import lightning as pl\n",
    "random_acc = []\n",
    "for i in range(100):\n",
    "    print(i)\n",
    "    np.random.seed(i)\n",
    "    label['tumor_stage_label'] = label.iloc[np.random.permutation(len(label)), :]['tumor_stage_label'].values\n",
    "    train_exp, test_exp, train_label, test_label = train_test_split(expression_data, label, test_size=0.2, random_state=42, stratify=label['early_stage'])\n",
    "    train_exp.to_csv('../data/Cleaned_data/Liver/train_exp.csv')\n",
    "    test_exp.to_csv('../data/Cleaned_data/Liver/test_exp.csv')\n",
    "    train_label.to_csv('../data/Cleaned_data/Liver/train_label.csv')\n",
    "    test_label.to_csv('../data/Cleaned_data/Liver/test_label.csv')\n",
    "\n",
    "    target_label = 'tumor_stage_label'\n",
    "    train_dataset = TCGADataset('../data/Cleaned_data/Liver/train_exp.csv', '../data/Cleaned_data/Liver/train_label.csv', target_label)\n",
    "    test_dateset = TCGADataset('../data/Cleaned_data/Liver/test_exp.csv', '../data/Cleaned_data/Liver/test_label.csv', target_label)\n",
    "    # train_dataset = TCGADataset('data/Cleaned_data/Colon/train_exp.csv', 'data/Cleaned_data/Colon/train_label.csv', target_label)\n",
    "    # test_dateset = TCGADataset('data/Cleaned_data/Colon/test_exp.csv', 'data/Cleaned_data/Colon/test_label.csv', target_label)\n",
    "\n",
    "    print(len(train_dataset))\n",
    "    print(len(test_dateset))\n",
    "    n_input = 397\n",
    "    n_hidden = 64\n",
    "    n_latent = 32\n",
    "    n_labels = 5\n",
    "    n_batch = train_dataset.n_batch\n",
    "    batch_size = 64\n",
    "    n_epoch = 400\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(test_dateset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "    # 定义模型\n",
    "    model = BulkVAE(\n",
    "        n_input=n_input,\n",
    "        n_batch=n_batch,\n",
    "        n_hidden=n_hidden,\n",
    "        n_latent=n_latent,\n",
    "        n_labels=n_labels,\n",
    "        n_layers=2,\n",
    "        dropout_rate=0.2,\n",
    "    )\n",
    "    optimizer = Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "    model=model.to('cuda')\n",
    "    max_acc = 0\n",
    "    for i in range(n_epoch):\n",
    "        total_correct = 0\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            data_batch, target_batch, batch_index, mean, variance = batch\n",
    "            data_batch = data_batch.to('cuda')\n",
    "            target_batch = target_batch.to('cuda')\n",
    "            mean = mean.to('cuda')\n",
    "            variance = variance.to('cuda')\n",
    "            batch_index = batch_index.to('cuda')\n",
    "            recon_loss, kl_z, kl_l, classification_loss, probs = model(data_batch, mean, variance, batch_index, target_batch)\n",
    "            mean_recon_loss = torch.mean(recon_loss)\n",
    "            mean_kl_z = torch.mean(kl_z)\n",
    "            mean_kl_l = torch.mean(kl_l)\n",
    "            # total_loss = classification_loss * 10\n",
    "            if i < 200:\n",
    "                total_loss = mean_recon_loss + mean_kl_z + mean_kl_l * 0.1\n",
    "            else:\n",
    "                total_loss = classification_loss * 50 + mean_recon_loss + mean_kl_z + mean_kl_l * 0.1\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            total_correct += torch.sum(torch.argmax(probs, dim=1) == target_batch)\n",
    "        # print(f\"Epoch: {i}, Loss: {total_loss}, Recon_loss: {mean_recon_loss}, KL_z: {mean_kl_z}, KL_l: {mean_kl_l}, Classification_loss: {classification_loss}\")\n",
    "        train_accu = total_correct\n",
    "        total_correct = 0\n",
    "        for batch in test_loader:\n",
    "            data_batch, target_batch, batch_index, mean, variance = batch\n",
    "            data_batch = data_batch.to('cuda')\n",
    "            target_batch = target_batch.to('cuda')\n",
    "            mean = mean.to('cuda')\n",
    "            variance = variance.to('cuda')\n",
    "            batch_index = batch_index.to('cuda')\n",
    "            recon_loss, kl_z, kl_l, probs = model(data_batch, mean, variance, batch_index)\n",
    "            prediction = torch.argmax(probs, dim=1)\n",
    "            total_correct += torch.sum(prediction == target_batch)\n",
    "        test_accu = total_correct\n",
    "        if max_acc < total_correct/len(test_dateset):\n",
    "            max_acc = total_correct/len(test_dateset)\n",
    "    random_acc.append(max_acc)\n",
    "    print(f'Random {i} max acc: {max_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "train_target = train_label['early_stage'].astype('category').cat.codes\n",
    "test_target = test_label['early_stage'].astype('category').cat.codes\n",
    "gbdt = GradientBoostingClassifier(n_estimators=1000, learning_rate=0.03, max_depth=3, random_state=42)\n",
    "gbdt.fit(train_exp, train_target)\n",
    "pred = gbdt.predict(test_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.11      0.14        38\n",
      "           1       0.56      0.75      0.64        57\n",
      "\n",
      "    accuracy                           0.49        95\n",
      "   macro avg       0.39      0.43      0.39        95\n",
      "weighted avg       0.42      0.49      0.44        95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_target, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tumor_stage_label\n",
       "2                    137\n",
       "3                    101\n",
       "1                     61\n",
       "4                     50\n",
       "0                     31\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.value_counts(['tumor_stage_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import TCGADataset\n",
    "target_label = 'sample_type'\n",
    "train_set = TCGADataset('../data/Cleaned_data/Colon/train_exp.csv', '../data/Cleaned_data/Colon/train_label.csv', target_label)\n",
    "test_set = TCGADataset('../data/Cleaned_data/Colon/test_exp.csv', '../data/Cleaned_data/Colon/test_label.csv', target_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = pd.read_csv('../data/Cleaned_data/Liver/train_label.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TCGA.ZS.A9CF.01A    0\n",
       "TCGA.G3.A25T.01A    1\n",
       "TCGA.MI.A75C.01A    1\n",
       "TCGA.UB.AA0V.01A    1\n",
       "TCGA.DD.AAVR.01A    0\n",
       "                   ..\n",
       "TCGA.CC.A5UE.01A    1\n",
       "TCGA.FV.A3R3.01A    1\n",
       "TCGA.DD.AAEK.01A    1\n",
       "TCGA.ZS.A9CF.02A    0\n",
       "TCGA.CC.A3MC.01A    1\n",
       "Length: 294, dtype: int8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label['median_surv'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    data_batch, target_batch, batch_index = zip(*batch)\n",
    "\n",
    "    batch_index = torch.tensor(batch_index, dtype=torch.float32).view(-1, 1)\n",
    "    data_batch = torch.stack(data_batch, dim=0)\n",
    "    target_batch = torch.stack(target_batch, dim=0)\n",
    "    library_sizes = torch.sum(data_batch, dim=1)\n",
    "\n",
    "    mean = torch.mean(library_sizes).expand(data_batch.size(0))\n",
    "    variance = torch.var(library_sizes).expand(data_batch.size(0))\n",
    "\n",
    "    return data_batch, target_batch, batch_index, mean, variance\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_set, batch_size=32, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 0.0000e+00, 1.4350e+03,  ..., 8.1400e+02, 3.7800e+02,\n",
      "         2.5300e+02],\n",
      "        [0.0000e+00, 3.2000e+01, 3.4610e+03,  ..., 4.9700e+02, 1.1720e+03,\n",
      "         6.6000e+02],\n",
      "        [5.4000e+01, 4.1000e+01, 2.6228e+04,  ..., 1.8900e+02, 7.2680e+03,\n",
      "         6.3440e+03],\n",
      "        ...,\n",
      "        [1.6000e+01, 5.0000e+00, 1.8170e+03,  ..., 6.0300e+02, 4.8900e+02,\n",
      "         2.7300e+02],\n",
      "        [6.0000e+00, 1.5000e+01, 9.0300e+02,  ..., 2.2200e+02, 2.0400e+02,\n",
      "         1.9800e+02],\n",
      "        [1.2000e+01, 1.5000e+01, 5.0490e+03,  ..., 2.4300e+03, 1.3650e+03,\n",
      "         7.3200e+02]]) tensor([0, 3, 1, 2, 2, 4, 1, 1, 3, 3, 2, 3, 2, 3, 2, 2, 4, 1, 2, 3, 3, 2, 4, 2,\n",
      "        2, 3, 3, 2, 2, 2, 3, 2]) tensor([[18.],\n",
      "        [ 4.],\n",
      "        [18.],\n",
      "        [14.],\n",
      "        [ 2.],\n",
      "        [19.],\n",
      "        [ 7.],\n",
      "        [ 3.],\n",
      "        [ 1.],\n",
      "        [19.],\n",
      "        [ 3.],\n",
      "        [19.],\n",
      "        [ 5.],\n",
      "        [ 9.],\n",
      "        [ 0.],\n",
      "        [ 1.],\n",
      "        [18.],\n",
      "        [14.],\n",
      "        [11.],\n",
      "        [ 0.],\n",
      "        [ 0.],\n",
      "        [19.],\n",
      "        [12.],\n",
      "        [ 0.],\n",
      "        [16.],\n",
      "        [19.],\n",
      "        [11.],\n",
      "        [18.],\n",
      "        [14.],\n",
      "        [18.],\n",
      "        [17.],\n",
      "        [ 7.]]) tensor([3033588.5000, 3033588.5000, 3033588.5000, 3033588.5000, 3033588.5000,\n",
      "        3033588.5000, 3033588.5000, 3033588.5000, 3033588.5000, 3033588.5000,\n",
      "        3033588.5000, 3033588.5000, 3033588.5000, 3033588.5000, 3033588.5000,\n",
      "        3033588.5000, 3033588.5000, 3033588.5000, 3033588.5000, 3033588.5000,\n",
      "        3033588.5000, 3033588.5000, 3033588.5000, 3033588.5000, 3033588.5000,\n",
      "        3033588.5000, 3033588.5000, 3033588.5000, 3033588.5000, 3033588.5000,\n",
      "        3033588.5000, 3033588.5000]) tensor([3.0811e+12, 3.0811e+12, 3.0811e+12, 3.0811e+12, 3.0811e+12, 3.0811e+12,\n",
      "        3.0811e+12, 3.0811e+12, 3.0811e+12, 3.0811e+12, 3.0811e+12, 3.0811e+12,\n",
      "        3.0811e+12, 3.0811e+12, 3.0811e+12, 3.0811e+12, 3.0811e+12, 3.0811e+12,\n",
      "        3.0811e+12, 3.0811e+12, 3.0811e+12, 3.0811e+12, 3.0811e+12, 3.0811e+12,\n",
      "        3.0811e+12, 3.0811e+12, 3.0811e+12, 3.0811e+12, 3.0811e+12, 3.0811e+12,\n",
      "        3.0811e+12, 3.0811e+12])\n"
     ]
    }
   ],
   "source": [
    "for data, target, batch_index, mean, variance in train_loader:\n",
    "    print(data, target, batch_index, mean, variance)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380\n"
     ]
    }
   ],
   "source": [
    "n_input = 398\n",
    "n_hidden = 64\n",
    "n_latent = 32\n",
    "n_batch = len(train_set)\n",
    "n_labels = 2\n",
    "print(n_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([10702743.0000,  4751273.0000, 25516744.0000, 12944392.0000,\n",
      "        11689364.0000, 19038540.0000,  7409312.0000, 12891787.0000,\n",
      "        16920158.0000, 25252558.0000,  4895038.0000, 24234324.0000,\n",
      "         5555599.0000,  7734252.0000, 17018790.0000, 17231220.0000,\n",
      "         6446980.0000, 20891880.0000, 11010207.0000,  7049693.0000,\n",
      "        27267102.0000,  9580864.0000,  7624444.0000, 11348685.0000,\n",
      "        12672920.0000, 16916026.0000,  6989196.5000, 12427053.0000,\n",
      "        17487262.0000, 12102446.0000,  7138230.5000, 13046132.0000],\n",
      "       grad_fn=<NegBackward0>) tensor([ 7.6726,  1.2526,  3.4310,  2.7497,  2.3621,  7.7888,  2.6538,  5.2459,\n",
      "        19.8198,  1.9583,  5.8649, 13.8285,  1.5784,  4.6270,  0.6725,  6.5620,\n",
      "         9.8480,  5.3109,  4.0237,  1.3213,  4.2406,  9.2825,  3.8794,  2.4801,\n",
      "         9.8914, 15.9775,  2.1207,  0.8508,  6.8058,  4.2357,  0.3519,  5.2665],\n",
      "       grad_fn=<SumBackward1>) tensor([863.2360, 863.2360, 863.2360, 859.4595, 835.7320, 839.1875, 863.2360,\n",
      "        863.2360, 855.3759, 863.2360, 863.2360, 863.2360, 859.7931, 863.2360,\n",
      "        842.4628, 863.2360, 863.2360, 863.2360, 863.2360, 861.2411, 828.9572,\n",
      "        855.3770, 863.2360, 834.3304, 843.5890, 851.1762, 863.2360, 827.2676,\n",
      "        863.2360, 863.2360, 863.2360, 863.2360], grad_fn=<SumBackward1>) tensor(0.6835, grad_fn=<DivBackward1>) tensor(13244151., grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from model import BulkVAE\n",
    "\n",
    "model = BulkVAE(n_input, n_batch, n_labels, n_hidden, n_latent)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1)\n",
    "\n",
    "for batch in train_loader:\n",
    "    optimizer.zero_grad()\n",
    "    data_batch, target_batch, batch_index, mean, variance = batch\n",
    "    recon_loss, kl_z, kl_l, classification_loss, probs = model(data_batch, mean, variance, batch_index, target_batch)\n",
    "    total_loss = torch.mean(recon_loss + kl_z + kl_l) + classification_loss\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    print(recon_loss, kl_z, kl_l, classification_loss, total_loss)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _convert_mean_disp_to_counts_logits(mu, theta, eps=1e-6):\n",
    "    r\"\"\"NB parameterizations conversion\n",
    "\n",
    "        :param mu: mean of the NB distribution.\n",
    "        :param theta: inverse overdispersion.\n",
    "        :param eps: constant used for numerical log stability.\n",
    "        :return: the number of failures until the experiment is stopped\n",
    "            and the success probability.\n",
    "    \"\"\"\n",
    "    assert (mu is None) == (\n",
    "        theta is None\n",
    "    ), \"If using the mu/theta NB parameterization, both parameters must be specified\"\n",
    "    logits = (mu + eps).log() - (theta + eps).log()\n",
    "    total_count = theta\n",
    "    return total_count, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negative Binomail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2000.]) tensor([-0.6931])\n",
      "tensor([[   -4.5771,  -240.6323,   -33.0034, -1534.3276,  -377.5938]])\n",
      "tensor([   -4.5776,  -240.6323,   -33.0029, -1534.3296,  -377.5938])\n"
     ]
    }
   ],
   "source": [
    "from distribution import NegativeBinomial\n",
    "from torch.distributions import NegativeBinomial as NB\n",
    "tens = torch.Tensor([1000, 2000, 1310, 4203, 2310])\n",
    "mu = torch.Tensor([1000])\n",
    "theta = torch.Tensor([2000])\n",
    "dist = NegativeBinomial(mu=mu, theta=theta)\n",
    "total_count, logits = _convert_mean_disp_to_counts_logits(mu, theta)\n",
    "print(total_count, logits)\n",
    "dist_t = NB(total_count=total_count, logits=logits)\n",
    "print(dist.log_prob(tens))\n",
    "print(dist_t.log_prob(tens))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TCGA Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Classifier\n",
    "n_input = 2000\n",
    "n_hidden = 512\n",
    "n_labels = 2\n",
    "n_layers = 2\n",
    "classifier = Classifier(n_input, n_hidden, n_labels, n_layers, dropout_rate=0.3)\n",
    "optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-4, weight_decay=1e-3)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(weight=torch.Tensor([10, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.3105263157894737\n",
      "tensor([0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
      "        0, 0, 1, 1, 1, 0, 0])\n",
      "Test Accuracy:  0.3263157894736842\n",
      "Train Accuracy:  0.43157894736842106\n",
      "tensor([1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
      "        1, 0, 1, 1, 0, 0, 0])\n",
      "Test Accuracy:  0.5263157894736842\n",
      "Train Accuracy:  0.5657894736842105\n",
      "tensor([1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
      "        1, 0, 0, 0, 0, 0, 1])\n",
      "Test Accuracy:  0.5684210526315789\n",
      "Train Accuracy:  0.65\n",
      "tensor([1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
      "        0, 0, 1, 0, 0, 1, 0])\n",
      "Test Accuracy:  0.6105263157894737\n",
      "Train Accuracy:  0.6736842105263158\n",
      "tensor([0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
      "        0, 0, 1, 0, 1, 1, 1])\n",
      "Test Accuracy:  0.6105263157894737\n",
      "Train Accuracy:  0.7052631578947368\n",
      "tensor([1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.6631578947368421\n",
      "Train Accuracy:  0.7605263157894737\n",
      "tensor([1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
      "        0, 0, 1, 1, 1, 0, 1])\n",
      "Test Accuracy:  0.6842105263157895\n",
      "Train Accuracy:  0.8\n",
      "tensor([0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.7368421052631579\n",
      "Train Accuracy:  0.8368421052631579\n",
      "tensor([0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1,\n",
      "        1, 0, 1, 1, 1, 0, 0])\n",
      "Test Accuracy:  0.6842105263157895\n",
      "Train Accuracy:  0.8421052631578947\n",
      "tensor([0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 0, 0, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.7684210526315789\n",
      "Train Accuracy:  0.85\n",
      "tensor([0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.7263157894736842\n",
      "Train Accuracy:  0.8473684210526315\n",
      "tensor([0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.6736842105263158\n",
      "Train Accuracy:  0.881578947368421\n",
      "tensor([1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
      "        1, 1, 0, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.7368421052631579\n",
      "Train Accuracy:  0.8947368421052632\n",
      "tensor([0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0,\n",
      "        1, 0, 0, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.6947368421052632\n",
      "Train Accuracy:  0.8736842105263158\n",
      "tensor([0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
      "        1, 0, 1, 1, 1, 1, 0])\n",
      "Test Accuracy:  0.6842105263157895\n",
      "Train Accuracy:  0.8947368421052632\n",
      "tensor([0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
      "        1, 0, 1, 1, 1, 1, 0])\n",
      "Test Accuracy:  0.6947368421052632\n",
      "Train Accuracy:  0.9157894736842105\n",
      "tensor([0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "        1, 0, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.7894736842105263\n",
      "Train Accuracy:  0.9052631578947369\n",
      "tensor([0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 0])\n",
      "Test Accuracy:  0.7578947368421053\n",
      "Train Accuracy:  0.9052631578947369\n",
      "tensor([0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "        0, 0, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.7789473684210526\n",
      "Train Accuracy:  0.8921052631578947\n",
      "tensor([0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
      "        1, 0, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.7578947368421053\n",
      "Train Accuracy:  0.9210526315789473\n",
      "tensor([0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.8105263157894737\n",
      "Train Accuracy:  0.9526315789473684\n",
      "tensor([0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        1, 0, 1, 1, 1, 1, 0])\n",
      "Test Accuracy:  0.7894736842105263\n",
      "Train Accuracy:  0.9315789473684211\n",
      "tensor([0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.8526315789473684\n",
      "Train Accuracy:  0.9552631578947368\n",
      "tensor([1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
      "        1, 0, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.7894736842105263\n",
      "Train Accuracy:  0.9605263157894737\n",
      "tensor([0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "        1, 0, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.7578947368421053\n",
      "Train Accuracy:  0.9552631578947368\n",
      "tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.8315789473684211\n",
      "Train Accuracy:  0.9605263157894737\n",
      "tensor([1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
      "        1, 0, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.7894736842105263\n",
      "Train Accuracy:  0.9421052631578948\n",
      "tensor([0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "        1, 0, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.8\n",
      "Train Accuracy:  0.9605263157894737\n",
      "tensor([0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.8\n",
      "Train Accuracy:  0.968421052631579\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "        1, 0, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.8315789473684211\n",
      "Train Accuracy:  0.9421052631578948\n",
      "tensor([0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        1, 1, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.8421052631578947\n",
      "Train Accuracy:  0.9710526315789474\n",
      "tensor([0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.8315789473684211\n",
      "Train Accuracy:  0.9736842105263158\n",
      "tensor([0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.8315789473684211\n",
      "Train Accuracy:  0.9605263157894737\n",
      "tensor([1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
      "        1, 0, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.8526315789473684\n",
      "Train Accuracy:  0.9763157894736842\n",
      "tensor([0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        1, 0, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.8210526315789474\n",
      "Train Accuracy:  0.9868421052631579\n",
      "tensor([1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.8210526315789474\n",
      "Train Accuracy:  0.9736842105263158\n",
      "tensor([0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.8421052631578947\n",
      "Train Accuracy:  0.9815789473684211\n",
      "tensor([0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.8421052631578947\n",
      "Train Accuracy:  0.9842105263157894\n",
      "tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        1, 0, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.8210526315789474\n",
      "Train Accuracy:  0.9789473684210527\n",
      "tensor([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
      "        1, 0, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.8210526315789474\n",
      "Train Accuracy:  0.968421052631579\n",
      "tensor([1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "        1, 1, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.8526315789473684\n",
      "Train Accuracy:  0.9947368421052631\n",
      "tensor([0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.8421052631578947\n",
      "Train Accuracy:  0.9815789473684211\n",
      "tensor([0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
      "        1, 0, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.7789473684210526\n",
      "Train Accuracy:  0.9736842105263158\n",
      "tensor([0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 0, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.8526315789473684\n",
      "Train Accuracy:  0.9868421052631579\n",
      "tensor([1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.8210526315789474\n",
      "Train Accuracy:  0.9868421052631579\n",
      "tensor([0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.8526315789473684\n",
      "Train Accuracy:  0.9736842105263158\n",
      "tensor([0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.8421052631578947\n",
      "Train Accuracy:  0.9842105263157894\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "        1, 1, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.8631578947368421\n",
      "Train Accuracy:  0.9894736842105263\n",
      "tensor([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.8736842105263158\n",
      "Train Accuracy:  0.9868421052631579\n",
      "tensor([0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1])\n",
      "Test Accuracy:  0.8842105263157894\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "for n in range(50):\n",
    "    correct_num = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        data_batch, target_batch, batch_index, mean, variance = batch\n",
    "        output = classifier(data_batch)\n",
    "        loss = loss_fn(output, target_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        probs = F.softmax(output, dim=1)\n",
    "        predictions = torch.argmax(probs, dim=1)\n",
    "        correct_num += (predictions == target_batch).sum()\n",
    "    print(\"Train Accuracy: \", correct_num.detach().numpy()/len(train_set))\n",
    "    train_acc.append(correct_num.detach().numpy()/len(train_set))\n",
    "\n",
    "    correct_num = 0\n",
    "    for batch in test_loader:\n",
    "        data_batch, target_batch, batch_index, mean, variance = batch\n",
    "        output = classifier(data_batch)\n",
    "        probs = F.softmax(output, dim=1)\n",
    "        predictions = torch.argmax(probs, dim=1)\n",
    "        correct_num += (predictions == target_batch).sum()\n",
    "    print(predictions)\n",
    "    print(\"Test Accuracy: \", correct_num.detach().numpy()/len(test_set))\n",
    "    test_acc.append(correct_num.detach().numpy()/len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(x=range(50), y=train_acc, label='Train Accuracy')\n",
    "sns.lineplot(x=range(50), y=test_acc, label='Test Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
